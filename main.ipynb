{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import equinox as eqx\n",
                "import equinox.nn as nn\n",
                "import jax\n",
                "import jax.numpy as jnp\n",
                "\n",
                "RELU_SLOPE = 0.2\n",
                "\n",
                "\n",
                "class Generator(eqx.Module):\n",
                "    layers: list\n",
                "    last_layer: eqx.nn.ConvTranspose2d\n",
                "\n",
                "    def __init__(self, hidden: int = 32, key=None):\n",
                "        k0, k1, k2, k3, k4 = jax.random.split(key, 5)\n",
                "\n",
                "        self.layers = [\n",
                "            nn.ConvTranspose2d(\n",
                "                64, 4 * hidden, kernel_size=4, stride=1, padding=\"VALID\", key=k0\n",
                "            ),\n",
                "            nn.ConvTranspose2d(\n",
                "                4 * hidden, 2 * hidden, kernel_size=4, stride=2, padding=\"SAME\", key=k1\n",
                "            ),\n",
                "            nn.ConvTranspose2d(2 * hidden, hidden, kernel_size=4, stride=2, padding=\"SAME\", key=k2),\n",
                "            nn.ConvTranspose2d(\n",
                "                hidden, hidden, kernel_size=4, stride=2, padding=3, key=k3\n",
                "            ),\n",
                "        ]\n",
                "\n",
                "        self.last_layer = nn.ConvTranspose2d(hidden, 1, kernel_size=1, stride=1, padding=\"SAME\", key=k4)\n",
                "\n",
                "    @jax.jit\n",
                "    def __call__(self, x):\n",
                "        for layer in self.layers:\n",
                "            x = layer(x)\n",
                "            x = jax.nn.leaky_relu(x, RELU_SLOPE) * jnp.sqrt(2)\n",
                "        x = self.last_layer(x)\n",
                "        return jax.nn.tanh(x)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Discriminator(eqx.Module):\n",
                "    layers: list\n",
                "\n",
                "    def __init__(self, hidden: int = 32, key=None):\n",
                "        k0, k1, k2, k3 = jax.random.split(key, 4)\n",
                "\n",
                "        self.layers = [\n",
                "            nn.Conv2d(1, hidden, kernel_size=3, stride=2, padding=1, key=k0),\n",
                "            nn.Conv2d(hidden, 2 * hidden, kernel_size=3, stride=2, padding=1, key=k1),\n",
                "            nn.Conv2d(2 * hidden, 4 * hidden, kernel_size=3, stride=2, padding=1, key=k2),\n",
                "            nn.Conv2d(4 * hidden, 1, kernel_size=4, padding=0, key=k3),\n",
                "        ]\n",
                "\n",
                "    @jax.jit\n",
                "    def __call__(self, x):\n",
                "        for layer in self.layers:\n",
                "            x = layer(x)\n",
                "            x = jax.nn.leaky_relu(x, RELU_SLOPE)\n",
                "        return jnp.reshape(x, (-1,))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<__main__.Tests at 0x7af57f56c290>"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "class Tests:\n",
                "\n",
                "    def __init__(self):\n",
                "        self.key = jax.random.PRNGKey(0)\n",
                "        \n",
                "        for func_name in dir(self):\n",
                "            if callable(getattr(self, func_name)) and (\"test_\" in func_name or \"_test\" in func_name):\n",
                "                self.key, k = jax.random.split(self.key)\n",
                "                func = getattr(self, func_name)\n",
                "                func(k)\n",
                "\n",
                "    def test_gan_size(self, key):\n",
                "        model = Generator(key=key)\n",
                "        random_input = jax.random.normal(key, shape=(256, 64, 1, 1))\n",
                "        output = jax.vmap(model)(random_input)\n",
                "        assert output.shape == (256, 1, 28, 28), f\"Expected output shape (N, 1, 28, 28), got {output.shape}\"\n",
                "\n",
                "    def test_disc_size(self, key):\n",
                "        model = Discriminator(key=key)\n",
                "        random_input = jax.random.normal(key, shape=(256, 1, 32, 32))\n",
                "        output = jax.vmap(model)(random_input)\n",
                "        assert output.shape == (256, 1), f\"Expected output shape (N, 1), got {output.shape}\"\n",
                "        \n",
                "\n",
                "Tests()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "@jax.jit\n",
                "@eqx.filter_value_and_grad\n",
                "def calc_gan_loss(model, disc, x, y):\n",
                "    output = jax.vmap(model)(x)\n",
                "\n",
                "    return -jnp.mean(jax.nn.log_sigmoid(jax.vmap(disc)(output)))\n",
                "\n",
                "@jax.jit\n",
                "@eqx.filter_value_and_grad\n",
                "def calc_disc_loss(disc, fake, real):\n",
                "    fake_pred = jax.vmap(disc)(fake)\n",
                "    real_pred = jax.vmap(disc)(real)\n",
                "\n",
                "    return (-jnp.mean(jax.nn.log_sigmoid(real_pred))-jnp.mean(jax.nn.log_sigmoid(-fake_pred))) / 2\n",
                "\n",
                "def make_step(model, disc, gan_optim, disc_optim, gan_opt_state, disc_opt_state, x, y):\n",
                "    gan_loss, grads = calc_gan_loss(model, disc, x, y)\n",
                "    updates, gan_opt_state = gan_optim.update(grads, gan_opt_state, model)\n",
                "    model = eqx.apply_updates(model, updates)\n",
                "\n",
                "    output = jax.vmap(model)(x)\n",
                "\n",
                "    disc_loss, grads = calc_disc_loss(disc, output, y)\n",
                "    updates, disc_opt_state = disc_optim.update(grads, disc_opt_state, disc)\n",
                "    disc = eqx.apply_updates(disc, updates)\n",
                "\n",
                "    return model, disc, gan_opt_state, disc_opt_state, gan_loss, disc_loss, output\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[CudaDevice(id=0)]\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "import datasets\n",
                "import optax\n",
                "import matplotlib.pyplot as plt\n",
                "from IPython.display import clear_output\n",
                "\n",
                "print(jax.devices())\n",
                "data = datasets.load_dataset(\"ylecun/mnist\").with_format(\"jax\")\n",
                "\n",
                "train_set, test_set = data[\"train\"], data[\"test\"]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "conv_general_dilated lhs feature dimension size divided by feature_group_count must equal the rhs input feature dimension size, but 1024 // 1 != 1.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[23], line 40\u001b[0m\n\u001b[1;32m     29\u001b[0m x, y \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(key\u001b[38;5;241m=\u001b[39mk, shape\u001b[38;5;241m=\u001b[39m(batch_size, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)), jnp\u001b[38;5;241m.\u001b[39mexpand_dims(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# print(y.device)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print(generator.shard)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m (\n\u001b[1;32m     33\u001b[0m     generator,\n\u001b[1;32m     34\u001b[0m     discriminator,\n\u001b[1;32m     35\u001b[0m     gan_opt_state,\n\u001b[1;32m     36\u001b[0m     disc_opt_state,\n\u001b[1;32m     37\u001b[0m     gan_loss,\n\u001b[1;32m     38\u001b[0m     disc_loss,\n\u001b[1;32m     39\u001b[0m     gan_output\n\u001b[0;32m---> 40\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mmake_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgan_optim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisc_optim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgan_opt_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisc_opt_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m step \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m*\u001b[39m train_set\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;241m+\u001b[39m i\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# # Log loss\u001b[39;00m\n",
                        "Cell \u001b[0;32mIn[4], line 23\u001b[0m, in \u001b[0;36mmake_step\u001b[0;34m(model, disc, gan_optim, disc_optim, gan_opt_state, disc_opt_state, x, y)\u001b[0m\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mapply_updates(model, updates)\n\u001b[1;32m     21\u001b[0m output \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(model)(x)\n\u001b[0;32m---> 23\u001b[0m disc_loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_disc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m updates, disc_opt_state \u001b[38;5;241m=\u001b[39m disc_optim\u001b[38;5;241m.\u001b[39mupdate(grads, disc_opt_state, disc)\n\u001b[1;32m     25\u001b[0m disc \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mapply_updates(disc, updates)\n",
                        "    \u001b[0;31m[... skipping hidden 30 frame]\u001b[0m\n",
                        "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mcalc_disc_loss\u001b[0;34m(disc, fake, real)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_value_and_grad\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcalc_disc_loss\u001b[39m(disc, fake, real):\n\u001b[1;32m     11\u001b[0m     fake_pred \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(disc)(fake)\n\u001b[0;32m---> 12\u001b[0m     real_pred \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m-\u001b[39mjnp\u001b[38;5;241m.\u001b[39mmean(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mlog_sigmoid(real_pred))\u001b[38;5;241m-\u001b[39mjnp\u001b[38;5;241m.\u001b[39mmean(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mlog_sigmoid(\u001b[38;5;241m-\u001b[39mfake_pred))) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
                        "    \u001b[0;31m[... skipping hidden 19 frame]\u001b[0m\n",
                        "Cell \u001b[0;32mIn[2], line 17\u001b[0m, in \u001b[0;36mDiscriminator.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 17\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m         x \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mleaky_relu(x, RELU_SLOPE)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mreshape(x, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n",
                        "File \u001b[0;32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/mnist-gan-jax/.venv/lib/python3.11/site-packages/equinox/nn/_conv.py:239\u001b[0m, in \u001b[0;36mConv.__call__\u001b[0;34m(self, x, key)\u001b[0m\n\u001b[1;32m    236\u001b[0m     padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding\n\u001b[1;32m    238\u001b[0m x \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 239\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_general_dilated\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlhs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrhs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_strides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrhs_dilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_group_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m x \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39msqueeze(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n",
                        "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
                        "File \u001b[0;32m~/mnist-gan-jax/.venv/lib/python3.11/site-packages/jax/_src/lax/convolution.py:374\u001b[0m, in \u001b[0;36m_conv_general_dilated_shape_rule\u001b[0;34m(lhs, rhs, window_strides, padding, lhs_dilation, rhs_dilation, dimension_numbers, feature_group_count, batch_group_count, **unused_kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mdefinitely_equal(quot, rhs\u001b[38;5;241m.\u001b[39mshape[dimension_numbers\u001b[38;5;241m.\u001b[39mrhs_spec[\u001b[38;5;241m1\u001b[39m]]):\n\u001b[1;32m    371\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv_general_dilated lhs feature dimension size divided by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_group_count must equal the rhs input feature dimension \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize, but \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m // \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 374\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(lhs_feature_count, feature_group_count,\n\u001b[1;32m    375\u001b[0m                               rhs\u001b[38;5;241m.\u001b[39mshape[dimension_numbers\u001b[38;5;241m.\u001b[39mrhs_spec[\u001b[38;5;241m1\u001b[39m]]))\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rhs\u001b[38;5;241m.\u001b[39mshape[dimension_numbers\u001b[38;5;241m.\u001b[39mrhs_spec[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m%\u001b[39m feature_group_count:\n\u001b[1;32m    377\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv_general_dilated rhs output feature dimension size must be a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    378\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiple of feature_group_count, but \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is not a multiple of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "\u001b[0;31mValueError\u001b[0m: conv_general_dilated lhs feature dimension size divided by feature_group_count must equal the rhs input feature dimension size, but 1024 // 1 != 1."
                    ]
                }
            ],
            "source": [
                "\n",
                "# # import cProfile\n",
                "# # import pstats  \n",
                "# def train():\n",
                "\n",
                "key = jax.random.PRNGKey(0)\n",
                "\n",
                "k1, k2 = jax.random.split(key)\n",
                "\n",
                "generator = Generator(key=k1)\n",
                "discriminator = Discriminator(key=k2)\n",
                "\n",
                "\n",
                "gan_optim = optax.adamw(1e-3)\n",
                "disc_optim = optax.adamw(1e-3)\n",
                "\n",
                "gan_opt_state = gan_optim.init(generator)\n",
                "disc_opt_state = disc_optim.init(discriminator)\n",
                "\n",
                "batch_size = 1024\n",
                "epochs = 2\n",
                "\n",
                "gan_losses = []\n",
                "disc_losses = []\n",
                "            \n",
                "\n",
                "for epoch in range(epochs):\n",
                "    for i, batch in enumerate(train_set.iter(batch_size=batch_size)):\n",
                "        key, k = jax.random.split(key)\n",
                "        x, y = jax.random.normal(key=k, shape=(batch_size, 64, 1, 1)), jnp.expand_dims(batch[\"image\"]/255, 0)\n",
                "        print(y.shape)\n",
                "        # print(y.device)\n",
                "        # print(generator.shard)\n",
                "        (\n",
                "            generator,\n",
                "            discriminator,\n",
                "            gan_opt_state,\n",
                "            disc_opt_state,\n",
                "            gan_loss,\n",
                "            disc_loss,\n",
                "            gan_output\n",
                "        ) = make_step(\n",
                "            generator,\n",
                "            discriminator,\n",
                "            gan_optim,\n",
                "            disc_optim,\n",
                "            gan_opt_state,\n",
                "            disc_opt_state,\n",
                "            x,\n",
                "            y,\n",
                "        )\n",
                "\n",
                "        step = epoch * train_set.num_rows + i\n",
                "        # # Log loss\n",
                "        gan_losses.append(gan_loss)\n",
                "        disc_losses.append(disc_loss)\n",
                "\n",
                "        clear_output(wait=True)\n",
                "    \n",
                "        plt.figure(figsize=(10, 5))\n",
                "        plt.plot(gan_losses, label=\"GAN Loss\")\n",
                "        plt.plot(disc_losses, label=\"Discriminator Loss\")\n",
                "        plt.xlabel(\"Iterations\")\n",
                "        plt.ylabel(\"Loss\")\n",
                "        plt.title(\"Training Losses\")\n",
                "        plt.legend()\n",
                "        plt.grid()\n",
                "        plt.show()\n",
                "\n",
                "        # Create the second figure for the GAN output\n",
                "        plt.figure(figsize=(5, 5))\n",
                "        plt.imshow(gan_output[0, 0], cmap=\"binary\")\n",
                "        plt.title(\"GAN Output\")\n",
                "        plt.axis(\"off\")\n",
                "        plt.show()\n",
                "\n",
                "# # Profile the training loop\n",
                "# cProfile.run(\"train()\", \"profile_results.prof\")\n",
                "\n",
                "# # Analyze the profiling results\n",
                "# stats = pstats.Stats(\"profile_results.prof\")\n",
                "# stats.strip_dirs()\n",
                "# stats.sort_stats(\"time\")  # Sort by time\n",
                "# stats.print_stats(10)  # Print the top 10 results\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
